#!/usr/bin/env python3
"""
RK3588 ONNXæ£€æµ‹è„šæœ¬ - ä¸éœ€è¦RKNNè½¬æ¢
ä½¿ç”¨ONNXRuntimeè¿›è¡ŒCPUæ¨ç†
"""

import cv2
import numpy as np
import time
import argparse
import os
import sys

def check_onnx_requirements():
    """æ£€æŸ¥ONNXè¿è¡Œç¯å¢ƒ"""
    try:
        import onnxruntime as ort
        print(f"âœ… ONNXRuntimeç‰ˆæœ¬: {ort.__version__}")
        
        # æ£€æŸ¥å¯ç”¨çš„æ‰§è¡Œæä¾›å™¨
        providers = ort.get_available_providers()
        print(f"âœ… å¯ç”¨æ‰§è¡Œå™¨: {providers}")
        
        if 'CPUExecutionProvider' in providers:
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°CPUæ‰§è¡Œå™¨")
            return False
            
    except ImportError:
        print("âŒ æœªå®‰è£…ONNXRuntimeï¼Œè¯·è¿è¡Œ:")
        print("pip3 install onnxruntime")
        return False

class ONNXFireDetector:
    def __init__(self, onnx_model_path, conf_threshold=0.4, nms_threshold=0.5):
        self.onnx_model_path = onnx_model_path
        self.conf_threshold = conf_threshold
        self.nms_threshold = nms_threshold
        self.session = None
        self.input_size = (640, 640)
        self.class_names = ['fire', 'smoke']
        
        self.load_model()
    
    def load_model(self):
        """åŠ è½½ONNXæ¨¡å‹"""
        try:
            import onnxruntime as ort
            
            print(f"ğŸ”„ åŠ è½½ONNXæ¨¡å‹: {self.onnx_model_path}")
            
            # åˆ›å»ºæ¨ç†ä¼šè¯ï¼Œä¼˜å…ˆä½¿ç”¨CPU
            providers = ['CPUExecutionProvider']
            self.session = ort.InferenceSession(self.onnx_model_path, providers=providers)
            
            # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
            self.input_name = self.session.get_inputs()[0].name
            self.output_names = [output.name for output in self.session.get_outputs()]
            
            input_shape = self.session.get_inputs()[0].shape
            print(f"âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   è¾“å…¥: {self.input_name} {input_shape}")
            print(f"   è¾“å‡º: {len(self.output_names)}ä¸ª")
            
            return True
            
        except Exception as e:
            print(f"âŒ ONNXæ¨¡å‹åŠ è½½é”™è¯¯: {e}")
            return False
    
    def preprocess(self, image):
        """å›¾åƒé¢„å¤„ç†"""
        # è°ƒæ•´å¤§å°
        input_image = cv2.resize(image, self.input_size)
        # é¢œè‰²ç©ºé—´è½¬æ¢
        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
        # å½’ä¸€åŒ–
        input_image = input_image.astype(np.float32) / 255.0
        # æ·»åŠ batchç»´åº¦å¹¶è½¬æ¢ä¸ºNCHWæ ¼å¼
        input_image = np.transpose(input_image, (2, 0, 1))  # HWC -> CHW
        input_image = np.expand_dims(input_image, axis=0)   # CHW -> NCHW
        
        return input_image
    
    def postprocess(self, outputs, original_shape):
        """åå¤„ç† - æ ‡å‡†YOLOv5æ ¼å¼"""
        try:
            # YOLOv5 ONNXè¾“å‡ºé€šå¸¸æ˜¯ (1, 25200, 85)
            predictions = outputs[0]  # è·å–ç¬¬ä¸€ä¸ªè¾“å‡º
            
            if len(predictions.shape) == 3:
                predictions = predictions[0]  # å»æ‰batchç»´åº¦: (25200, 85)
            
            boxes = []
            scores = []
            class_ids = []
            
            h, w = original_shape[:2]
            x_scale = w / self.input_size[0]
            y_scale = h / self.input_size[1]
            
            for detection in predictions:
                # YOLOv5æ ¼å¼: [x_center, y_center, width, height, confidence, class1_score, class2_score, ...]
                confidence = detection[4]
                
                if confidence > self.conf_threshold:
                    # æå–è¾¹æ¡†åæ ‡
                    x_center = detection[0] * x_scale
                    y_center = detection[1] * y_scale
                    width = detection[2] * x_scale
                    height = detection[3] * y_scale
                    
                    # è½¬æ¢ä¸ºå·¦ä¸Šè§’åæ ‡
                    x1 = int(x_center - width / 2)
                    y1 = int(y_center - height / 2)
                    x2 = int(x_center + width / 2)
                    y2 = int(y_center + height / 2)
                    
                    # è·å–ç±»åˆ«åˆ†æ•°
                    class_scores = detection[5:]
                    class_id = np.argmax(class_scores)
                    class_score = class_scores[class_id]
                    
                    final_score = confidence * class_score
                    
                    if final_score > self.conf_threshold:
                        boxes.append([x1, y1, x2, y2])
                        scores.append(float(final_score))
                        class_ids.append(int(class_id))
            
            # NMSå»é‡
            if len(boxes) > 0:
                indices = cv2.dnn.NMSBoxes(boxes, scores, self.conf_threshold, self.nms_threshold)
                
                if len(indices) > 0:
                    final_boxes = [boxes[i] for i in indices.flatten()]
                    final_scores = [scores[i] for i in indices.flatten()]
                    final_class_ids = [class_ids[i] for i in indices.flatten()]
                    
                    return final_boxes, final_scores, final_class_ids
            
        except Exception as e:
            print(f"åå¤„ç†é”™è¯¯: {e}")
        
        return [], [], []
    
    def detect(self, image):
        """æ‰§è¡Œæ£€æµ‹"""
        if self.session is None:
            return [], [], []
        
        try:
            # é¢„å¤„ç†
            input_image = self.preprocess(image)
            
            # æ¨ç†
            outputs = self.session.run(self.output_names, {self.input_name: input_image})
            
            # åå¤„ç†
            boxes, scores, class_ids = self.postprocess(outputs, image.shape)
            
            return boxes, scores, class_ids
            
        except Exception as e:
            print(f"æ£€æµ‹é”™è¯¯: {e}")
            return [], [], []

def main():
    print("ğŸ”¥ RK3588 ONNXç«ç¾çƒŸé›¾æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 40)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_onnx_requirements():
        print("\nğŸ’¡ å®‰è£…ONNXRuntime:")
        print("pip3 install onnxruntime")
        return
    
    parser = argparse.ArgumentParser(description='RK3588 ONNXç«ç¾çƒŸé›¾æ£€æµ‹')
    parser.add_argument('--source', type=str, default='0', help='è¾“å…¥æº')
    parser.add_argument('--weights', type=str, default='./models/best_final_clean.onnx', help='ONNXæ¨¡å‹è·¯å¾„')
    parser.add_argument('--conf', type=float, default=0.4, help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--nms', type=float, default=0.5, help='NMSé˜ˆå€¼')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.weights):
        print(f"âŒ ONNXæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.weights}")
        print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„")
        return
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = ONNXFireDetector(args.weights, args.conf, args.nms)
    
    if detector.session is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    # æ‰“å¼€è§†é¢‘æº
    print(f"\nğŸ“¹ æ‰“å¼€è§†é¢‘æº: {args.source}")
    if args.source.isdigit():
        source = int(args.source)
    else:
        source = args.source
    
    cap = cv2.VideoCapture(source)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æº")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS) or 25
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height} @ {fps:.1f}FPS")
    
    print("ğŸš€ CPUæ¨ç†å¯åŠ¨...")
    print("âš ï¸  æ³¨æ„: CPUæ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…")
    
    frame_count = 0
    total_time = 0
    detection_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ è¯»å–è§†é¢‘å¸§å¤±è´¥")
                break
            
            frame_count += 1
            
            # æ£€æµ‹
            start_time = time.time()
            boxes, scores, class_ids = detector.detect(frame)
            detect_time = time.time() - start_time
            total_time += detect_time
            
            detection_count += len(boxes)
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            for i, (box, score, class_id) in enumerate(zip(boxes, scores, class_ids)):
                x1, y1, x2, y2 = box
                label = f"{detector.class_names[class_id]}: {score:.2f}"
                
                # é¢œè‰²è®¾ç½®
                color = (0, 255, 0) if class_id == 0 else (0, 0, 255)  # ç»¿è‰²=ç«ç¾ï¼Œçº¢è‰²=çƒŸé›¾
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # æ˜¾ç¤ºFPSå’Œæ€§èƒ½ä¿¡æ¯
            if frame_count > 0:
                avg_fps = frame_count / total_time
                current_fps = 1.0 / detect_time if detect_time > 0 else 0
                fps_text = f"CPU FPS: {current_fps:.1f} | Avg: {avg_fps:.1f} | Inference: {detect_time*1000:.0f}ms"
            else:
                fps_text = "CPU FPS: è®¡ç®—ä¸­..."
            
            cv2.putText(frame, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡
            stats_text = f"Detections: {len(boxes)} | Total: {detection_count}"
            cv2.putText(frame, stats_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            # æ˜¾ç¤ºå›¾åƒ
            cv2.imshow('ONNX Fire Detection (CPU)', frame)
            
            # æŒ‰'q'é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
            # æ¯30å¸§æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            if frame_count % 30 == 0:
                avg_fps = frame_count / total_time
                print(f"ğŸ“Š å·²å¤„ç† {frame_count} å¸§ï¼Œå¹³å‡FPS: {avg_fps:.1f}ï¼Œæ£€æµ‹åˆ° {detection_count} ä¸ªç›®æ ‡")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ£€æµ‹ä¸­æ–­")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        
        if frame_count > 0:
            avg_fps = frame_count / total_time
            print(f"\nğŸ“Š æ£€æµ‹å®Œæˆ:")
            print(f"   æ€»å¸§æ•°: {frame_count}")
            print(f"   å¹³å‡FPS: {avg_fps:.1f}")
            print(f"   æ£€æµ‹åˆ°ç›®æ ‡: {detection_count} ä¸ª")
            print(f"   æ€»è€—æ—¶: {total_time:.1f}ç§’")

if __name__ == '__main__':
    main()