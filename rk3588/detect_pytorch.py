#!/usr/bin/env python3
"""
ÁÅ´ÁÅæÁÉüÈõæÊ£ÄÊµã - PyTorchÁâàÊú¨
ÊîØÊåÅYOLOv5 .ptÊ®°ÂûãÊ†ºÂºèÔºåCPUÊé®ÁêÜ
"""

import argparse
import time
import cv2
import numpy as np
from pathlib import Path

def check_pytorch():
    """Ê£ÄÊü•PyTorchÊòØÂê¶ÂèØÁî®"""
    try:
        import torch
        return True, torch.__version__
    except ImportError:
        return False, None

def load_model(weights):
    """Âä†ËΩΩPyTorchÊ®°Âûã"""
    try:
        import torch
        
        # Âä†ËΩΩÊ®°Âûã
        model = torch.hub.load('.', 'custom', path=weights, source='local', force_reload=True)
        model.conf = 0.4  # ÁΩÆ‰ø°Â∫¶ÈòàÂÄº
        model.iou = 0.45  # NMS IOUÈòàÂÄº
        
        print(f"‚úÖ ÊàêÂäüÂä†ËΩΩPyTorchÊ®°Âûã: {weights}")
        print(f"üìä Ê®°ÂûãÁ±ªÂà´: {model.names}")
        return model
        
    except Exception as e:
        print(f"‚ùå Âä†ËΩΩÊ®°ÂûãÂ§±Ë¥•: {e}")
        return None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--source', type=str, default='0', help='ËæìÂÖ•Ê∫ê')
    parser.add_argument('--weights', type=str, required=True, help='Ê®°ÂûãÊùÉÈáçË∑ØÂæÑ')
    parser.add_argument('--conf', type=float, default=0.4, help='ÁΩÆ‰ø°Â∫¶ÈòàÂÄº')
    parser.add_argument('--show', action='store_true', help='ÊòæÁ§∫ÁªìÊûú')
    parser.add_argument('--save', action='store_true', help='‰øùÂ≠òÁªìÊûú')
    args = parser.parse_args()

    print("üî• ÁÅ´ÁÅæÊ£ÄÊµãÁ≥ªÁªü - PyTorchÁâàÊú¨")
    print("=" * 50)

    # Ê£ÄÊü•PyTorch
    pytorch_ok, version = check_pytorch()
    if not pytorch_ok:
        print("‚ùå PyTorchÊú™ÂÆâË£Ö")
        print("üí° ÂÆâË£ÖÂëΩ‰ª§: pip3 install torch torchvision")
        return

    print(f"‚úÖ PyTorchÁâàÊú¨: {version}")

    # Âä†ËΩΩÊ®°Âûã
    model = load_model(args.weights)
    if model is None:
        return

    # ËÆæÁΩÆÁΩÆ‰ø°Â∫¶
    model.conf = args.conf

    # ÊâìÂºÄËßÜÈ¢ëÊ∫ê
    cap = cv2.VideoCapture(args.source)
    if not cap.isOpened():
        print(f"‚ùå Êó†Ê≥ïÊâìÂºÄËßÜÈ¢ëÊ∫ê: {args.source}")
        return

    print(f"‚úÖ ËßÜÈ¢ëÊ∫êÂ∑≤ËøûÊé•: {args.source}")

    # Ê£ÄÊµãÂæ™ÁéØ
    frame_count = 0
    fps_counter = 0
    fps_start_time = time.time()

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ö†Ô∏è  Êó†Ê≥ïËØªÂèñÂ∏ß")
                break

            frame_count += 1
            
            # YOLOv5Êé®ÁêÜ
            start_time = time.time()
            results = model(frame)
            inference_time = time.time() - start_time

            # Ëß£ÊûêÁªìÊûú
            detections = results.pandas().xyxy[0]
            
            # ÁªòÂà∂Ê£ÄÊµãÊ°Ü
            annotated_frame = frame.copy()
            fire_count = 0
            smoke_count = 0
            
            for _, detection in detections.iterrows():
                x1, y1, x2, y2 = map(int, [detection['xmin'], detection['ymin'], 
                                          detection['xmax'], detection['ymax']])
                conf = detection['confidence']
                class_name = detection['name']
                
                if class_name == 'fire':
                    color = (0, 0, 255)  # Á∫¢Ëâ≤
                    fire_count += 1
                elif class_name == 'smoke':
                    color = (128, 128, 128)  # ÁÅ∞Ëâ≤
                    smoke_count += 1
                else:
                    continue
                
                # ÁªòÂà∂ËæπÁïåÊ°Ü
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                
                # ÁªòÂà∂Ê†áÁ≠æ
                label = f"{class_name}: {conf:.2f}"
                cv2.putText(annotated_frame, label, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

            # ËÆ°ÁÆóFPS
            fps_counter += 1
            if time.time() - fps_start_time >= 1.0:
                fps = fps_counter / (time.time() - fps_start_time)
                fps_counter = 0
                fps_start_time = time.time()
                
                # ÊâìÂç∞Áä∂ÊÄÅ
                print(f"Â∏ß{frame_count:6d} | "
                      f"Êé®ÁêÜ: {inference_time*1000:5.1f}ms | "
                      f"FPS: {fps:4.1f} | "
                      f"ÁÅ´ÁÅæ: {fire_count} | "
                      f"ÁÉüÈõæ: {smoke_count}")

            # ÊòæÁ§∫ÁªìÊûú
            if args.show:
                # Ê∑ªÂä†‰ø°ÊÅØÊñáÊú¨
                info_text = f"PyTorch CPU | FPS: {fps:.1f} | Fire: {fire_count} | Smoke: {smoke_count}"
                cv2.putText(annotated_frame, info_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                cv2.imshow('ÁÅ´ÁÅæÊ£ÄÊµã', annotated_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            # ‰øùÂ≠òÁªìÊûúÔºàÂèØÈÄâÔºâ
            if args.save and (fire_count > 0 or smoke_count > 0):
                timestamp = int(time.time())
                save_path = f"detection_{timestamp}.jpg"
                cv2.imwrite(save_path, annotated_frame)

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Ê£ÄÊµã‰∏≠Êñ≠")
    finally:
        cap.release()
        if args.show:
            cv2.destroyAllWindows()
        print("‚úÖ ËµÑÊ∫êÂ∑≤Ê∏ÖÁêÜ")

if __name__ == '__main__':
    main()