#!/usr/bin/env python3
"""
RK3588 RKNNæ¨¡å‹æ¨ç†è„šæœ¬ - ä½¿ç”¨é¢„è½¬æ¢çš„æœ€ç»ˆæ¨¡å‹
ä½¿ç”¨NPUåŠ é€Ÿè¿›è¡Œç«ç¾çƒŸé›¾æ£€æµ‹
æ¨¡å‹æ–‡ä»¶: best_final_clean.rknn (å·²ä¼˜åŒ–ï¼Œæ— éœ€è½¬æ¢)
"""

import cv2
import numpy as np
import time
import argparse
import os
from rknn.api import RKNN
import threading
from datetime import datetime

class RKNNFireDetector:
    def __init__(self, rknn_model_path, conf_threshold=0.4, nms_threshold=0.5):
        self.rknn_model_path = rknn_model_path
        self.conf_threshold = conf_threshold
        self.nms_threshold = nms_threshold
        self.rknn = RKNN()
        self.model_loaded = False
        self.input_size = (640, 640)
        
        # ç±»åˆ«åç§°ï¼ˆæ ¹æ®æ‚¨çš„æ¨¡å‹è°ƒæ•´ï¼‰
        self.class_names = ['fire', 'smoke']  # ç«ç¾å’ŒçƒŸé›¾
        
        self.load_model()
    
    def load_model(self):
        """åŠ è½½RKNNæ¨¡å‹"""
        try:
            print(f"ğŸ”„ åŠ è½½RKNNæ¨¡å‹: {self.rknn_model_path}")
            
            # åŠ è½½RKNNæ¨¡å‹
            ret = self.rknn.load_rknn(self.rknn_model_path)
            if ret != 0:
                print('âŒ åŠ è½½RKNNæ¨¡å‹å¤±è´¥')
                return False
            
            # åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ
            ret = self.rknn.init_runtime()
            if ret != 0:
                print('âŒ åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒå¤±è´¥')
                return False
            
            self.model_loaded = True
            print('âœ… RKNNæ¨¡å‹åŠ è½½æˆåŠŸï¼ŒNPUåŠ é€Ÿå·²å¯ç”¨')
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½é”™è¯¯: {e}")
            return False
    
    def preprocess(self, image):
        """å›¾åƒé¢„å¤„ç†"""
        # è°ƒæ•´å¤§å°
        input_image = cv2.resize(image, self.input_size)
        # é¢œè‰²ç©ºé—´è½¬æ¢
        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
        return input_image
    
    def postprocess(self, outputs, original_shape):
        """åå¤„ç†ï¼Œè§£æRKNNè¾“å‡º"""
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„å…·ä½“æ¨¡å‹è¾“å‡ºæ ¼å¼è¿›è¡Œè°ƒæ•´
            # é€šå¸¸YOLOv5çš„è¾“å‡ºæ˜¯ (1, 25200, 85) çš„å½¢çŠ¶
            predictions = outputs[0]
            
            # è§£æé¢„æµ‹ç»“æœ
            boxes = []
            scores = []
            class_ids = []
            
            h, w = original_shape[:2]
            x_scale = w / self.input_size[0]
            y_scale = h / self.input_size[1]
            
            for detection in predictions:
                # æå–ç½®ä¿¡åº¦å’Œç±»åˆ«åˆ†æ•°
                confidence = detection[4]
                if confidence > self.conf_threshold:
                    # æå–è¾¹æ¡†åæ ‡
                    x_center = detection[0] * x_scale
                    y_center = detection[1] * y_scale
                    width = detection[2] * x_scale
                    height = detection[3] * y_scale
                    
                    # è½¬æ¢ä¸ºå·¦ä¸Šè§’åæ ‡
                    x1 = int(x_center - width / 2)
                    y1 = int(y_center - height / 2)
                    x2 = int(x_center + width / 2)
                    y2 = int(y_center + height / 2)
                    
                    # è·å–æœ€é«˜åˆ†ç±»åˆ«
                    class_scores = detection[5:]
                    class_id = np.argmax(class_scores)
                    class_score = class_scores[class_id]
                    
                    final_score = confidence * class_score
                    
                    if final_score > self.conf_threshold:
                        boxes.append([x1, y1, x2, y2])
                        scores.append(float(final_score))
                        class_ids.append(int(class_id))
            
            # NMSå»é‡
            if len(boxes) > 0:
                indices = cv2.dnn.NMSBoxes(boxes, scores, self.conf_threshold, self.nms_threshold)
                
                final_boxes = []
                final_scores = []
                final_class_ids = []
                
                if len(indices) > 0:
                    for i in indices.flatten():
                        final_boxes.append(boxes[i])
                        final_scores.append(scores[i])
                        final_class_ids.append(class_ids[i])
                
                return final_boxes, final_scores, final_class_ids
            
        except Exception as e:
            print(f"åå¤„ç†é”™è¯¯: {e}")
        
        return [], [], []
    
    def detect(self, image):
        """æ‰§è¡Œæ£€æµ‹"""
        if not self.model_loaded:
            return [], [], []
        
        try:
            # é¢„å¤„ç†
            input_image = self.preprocess(image)
            
            # æ¨ç†
            outputs = self.rknn.inference(inputs=[input_image])
            
            # åå¤„ç†
            boxes, scores, class_ids = self.postprocess(outputs, image.shape)
            
            return boxes, scores, class_ids
            
        except Exception as e:
            print(f"æ£€æµ‹é”™è¯¯: {e}")
            return [], [], []
    
    def draw_results(self, image, boxes, scores, class_ids):
        """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        for i, (box, score, class_id) in enumerate(zip(boxes, scores, class_ids)):
            x1, y1, x2, y2 = box
            
            # é€‰æ‹©é¢œè‰²
            color = (0, 0, 255) if class_id == 0 else (0, 255, 255)  # çº¢è‰²=ç«ç¾ï¼Œé»„è‰²=çƒŸé›¾
            
            # ç»˜åˆ¶è¾¹æ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{self.class_names[class_id]}: {score:.2f}"
            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(image, (x1, y1 - text_height - 10), (x1 + text_width, y1), color, -1)
            cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return image
    
    def run_detection(self, source, save_video=False, show_display=True):
        """è¿è¡Œæ£€æµ‹å¾ªç¯"""
        # æ‰“å¼€è§†é¢‘æº
        if source == '0' or source == 0:
            cap = cv2.VideoCapture(0)
        elif source.startswith('rtsp://'):
            cap = cv2.VideoCapture(source, cv2.CAP_FFMPEG)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        else:
            cap = cv2.VideoCapture(source)
        
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æº: {source}")
            return
        
        # è·å–è§†é¢‘ä¿¡æ¯
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"ğŸ“¹ è§†é¢‘æºä¿¡æ¯: {width}x{height} @ {fps:.2f}FPS")
        print("ğŸš€ NPUåŠ é€Ÿæ¨ç†å¯åŠ¨...")
        
        # è§†é¢‘ä¿å­˜è®¾ç½®
        out = None
        if save_video:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            out_filename = f"rknn_fire_detection_{timestamp}.mp4"
            out = cv2.VideoWriter(out_filename, fourcc, 20.0, (width, height))
            print(f"ğŸ’¾ ä¿å­˜è§†é¢‘åˆ°: {out_filename}")
        
        # FPSè®¡ç®—
        fps_counter = 0
        start_time = time.time()
        detection_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                fps_counter += 1
                
                # æ‰§è¡Œæ£€æµ‹
                detect_start = time.time()
                boxes, scores, class_ids = self.detect(frame)
                detect_time = time.time() - detect_start
                
                # ç»˜åˆ¶ç»“æœ
                if len(boxes) > 0:
                    frame = self.draw_results(frame, boxes, scores, class_ids)
                    detection_count += len(boxes)
                    
                    # æ‰“å°æ£€æµ‹ä¿¡æ¯
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    print(f"ğŸ”¥ [{timestamp}] NPUæ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡ (æ¨ç†æ—¶é—´: {detect_time*1000:.1f}ms)")
                
                # è®¡ç®—å¹¶æ˜¾ç¤ºFPS
                elapsed = time.time() - start_time
                if elapsed > 1.0:
                    current_fps = fps_counter / elapsed
                    fps_counter = 0
                    start_time = time.time()
                    
                    # åœ¨ç”»é¢ä¸Šæ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
                    fps_text = f"NPU FPS: {current_fps:.1f} | Inference: {detect_time*1000:.1f}ms"
                    cv2.putText(frame, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                detection_info = f"Detections: {detection_count}"
                cv2.putText(frame, detection_info, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # ä¿å­˜è§†é¢‘å¸§
                if save_video and out:
                    out.write(frame)
                
                # æ˜¾ç¤ºå›¾åƒ
                if show_display:
                    cv2.imshow('RK3588 NPU Fire Detection', frame)
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q') or key == 27:
                        break
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸  æ£€æµ‹åœæ­¢")
        
        finally:
            cap.release()
            if out:
                out.release()
            if show_display:
                cv2.destroyAllWindows()
            
            print(f"ğŸ“Š æ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {detection_count} ä¸ªç›®æ ‡")
    
    def __del__(self):
        if hasattr(self, 'rknn'):
            self.rknn.release()

def main():
    parser = argparse.ArgumentParser(description='RK3588 NPUç«ç¾çƒŸé›¾æ£€æµ‹')
    parser.add_argument('--source', type=str, default='0', help='è¾“å…¥æº')
    parser.add_argument('--weights', type=str, default='./models/best_final_clean.rknn', help='RKNNæ¨¡å‹è·¯å¾„')
    parser.add_argument('--conf', type=float, default=0.4, help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--nms', type=float, default=0.5, help='NMSé˜ˆå€¼')
    parser.add_argument('--save-vid', action='store_true', help='ä¿å­˜æ£€æµ‹è§†é¢‘')
    parser.add_argument('--no-display', action='store_true', help='ä¸æ˜¾ç¤ºæ£€æµ‹çª—å£')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.weights):
        print(f"âŒ RKNNæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.weights}")
        print("è¯·å…ˆè¿è¡Œæ¨¡å‹è½¬æ¢:")
        print("python3 convert_to_rknn.py --input ./best.pt")
        return
    
    print("ğŸš€ RK3588 NPUç«ç¾çƒŸé›¾æ£€æµ‹ç³»ç»Ÿ")
    print(f"   RKNNæ¨¡å‹: {args.weights}")
    print(f"   è¾“å…¥æº: {args.source}")
    print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {args.conf}")
    print("-" * 50)
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = RKNNFireDetector(args.weights, args.conf, args.nms)
    
    # è¿è¡Œæ£€æµ‹
    detector.run_detection(
        source=args.source,
        save_video=args.save_vid,
        show_display=not args.no_display
    )

if __name__ == '__main__':
    main()