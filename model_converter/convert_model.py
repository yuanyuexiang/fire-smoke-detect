#!/usr/bin/env python3
"""
RKNNæ¨¡å‹è½¬æ¢ä¸»è„šæœ¬
ä¸“é—¨ç”¨äºåœ¨æ™®é€šUbuntuç³»ç»Ÿä¸Šè½¬æ¢YOLOv5æ¨¡å‹ä¸ºRKNNæ ¼å¼
"""

import os
import sys
import argparse
import logging
import torch
import numpy as np
from rknn.api import RKNN
import traceback
from datetime import datetime

# è®¾ç½®æ—¥å¿—
def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f"conversion_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

class YOLOv5ToRKNN:
    def __init__(self, verbose=True):
        """åˆå§‹åŒ–è½¬æ¢å™¨"""
        self.logger = setup_logging()
        self.rknn = RKNN(verbose=verbose)
        self.logger.info("RKNN Toolkit2 initialized")
        
    def load_pytorch_model(self, model_path):
        """åŠ è½½PyTorchæ¨¡å‹"""
        self.logger.info(f"Loading PyTorch model: {model_path}")
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
        
        try:
            device = torch.device('cpu')
            checkpoint = torch.load(model_path, map_location=device)
            
            if isinstance(checkpoint, dict):
                if 'model' in checkpoint:
                    model = checkpoint['model'].float()
                    self.logger.info("YOLOv5 training checkpoint detected")
                else:
                    model = checkpoint
                    self.logger.info("Standard PyTorch model detected")
            else:
                model = checkpoint
                self.logger.info("Direct model object detected")
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            if hasattr(model, 'eval'):
                model.eval()
            
            # è®¾ç½®å¯¼å‡ºæ¨¡å¼
            if hasattr(model, 'model'):
                for m in model.model.modules():
                    if hasattr(m, 'export'):
                        m.export = True
            else:
                for m in model.modules():
                    if hasattr(m, 'export'):
                        m.export = True
            
            self.logger.info("Model loaded and configured for export")
            return model
            
        except Exception as e:
            self.logger.error(f"Failed to load model: {e}")
            raise
    
    def export_to_onnx(self, model, onnx_path, input_size=(1, 3, 640, 640)):
        """å¯¼å‡ºä¸ºONNXæ ¼å¼"""
        self.logger.info(f"Exporting to ONNX: {onnx_path}")
        self.logger.info(f"Input size: {input_size}")
        
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(os.path.dirname(onnx_path), exist_ok=True)
            
            # åˆ›å»ºç¤ºä¾‹è¾“å…¥
            dummy_input = torch.randn(input_size)
            
            # å¯¼å‡ºONNX
            with torch.no_grad():
                torch.onnx.export(
                    model,
                    dummy_input,
                    onnx_path,
                    export_params=True,
                    opset_version=11,
                    do_constant_folding=True,
                    input_names=['input'],
                    output_names=['output'],
                    dynamic_axes={
                        'input': {0: 'batch_size'},
                        'output': {0: 'batch_size'}
                    },
                    verbose=False
                )
            
            # éªŒè¯ONNXæ–‡ä»¶
            import onnx
            onnx_model = onnx.load(onnx_path)
            onnx.checker.check_model(onnx_model)
            
            file_size = os.path.getsize(onnx_path) / (1024 * 1024)
            self.logger.info(f"ONNX export successful: {file_size:.1f} MB")
            return True
            
        except Exception as e:
            self.logger.error(f"ONNX export failed: {e}")
            traceback.print_exc()
            return False
    
    def convert_to_rknn(self, onnx_path, rknn_path, input_size_list=[[1,3,640,640]], quantize=False):
        """è½¬æ¢ONNXä¸ºRKNNæ ¼å¼"""
        self.logger.info(f"Converting ONNX to RKNN: {onnx_path} -> {rknn_path}")
        
        try:
            # RKNNé…ç½®
            self.logger.info("Configuring RKNN conversion parameters...")
            ret = self.rknn.config(
                target_platform='rk3588',
                optimization_level=2,
                output_optimize=1,
                quantize_input_node=quantize,
                quantize_output_node=quantize,
                compress_weight=True
            )
            
            if ret != 0:
                raise RuntimeError("RKNN configuration failed")
            
            # åŠ è½½ONNXæ¨¡å‹
            self.logger.info("Loading ONNX model...")
            ret = self.rknn.load_onnx(model=onnx_path)
            if ret != 0:
                raise RuntimeError("Failed to load ONNX model")
            
            # æ„å»ºRKNNæ¨¡å‹
            self.logger.info("Building RKNN model...")
            if quantize:
                self.logger.info("Quantization enabled")
            
            ret = self.rknn.build(do_quantization=quantize)
            if ret != 0:
                raise RuntimeError("RKNN model build failed")
            
            # å¯¼å‡ºRKNNæ¨¡å‹
            self.logger.info("Exporting RKNN model...")
            os.makedirs(os.path.dirname(rknn_path), exist_ok=True)
            ret = self.rknn.export_rknn(rknn_path)
            if ret != 0:
                raise RuntimeError("RKNN model export failed")
            
            file_size = os.path.getsize(rknn_path) / (1024 * 1024)
            self.logger.info(f"RKNN export successful: {file_size:.1f} MB")
            
            # ç®€å•éªŒè¯
            self.logger.info("Performing basic validation...")
            ret = self.rknn.init_runtime()
            if ret == 0:
                # åˆ›å»ºæµ‹è¯•è¾“å…¥
                input_data = [np.random.randint(0, 256, input_size_list[0], dtype=np.uint8)]
                outputs = self.rknn.inference(inputs=input_data)
                if outputs is not None:
                    self.logger.info(f"Validation passed - Output shapes: {[out.shape for out in outputs]}")
                else:
                    self.logger.warning("Validation failed - No outputs")
            else:
                self.logger.warning("Cannot initialize runtime (may not be on RK3588)")
            
            return True
            
        except Exception as e:
            self.logger.error(f"RKNN conversion failed: {e}")
            traceback.print_exc()
            return False
        finally:
            self.rknn.release()
    
    def convert_full_pipeline(self, pytorch_path, output_dir, input_size=(1, 3, 640, 640), quantize=False):
        """å®Œæ•´çš„è½¬æ¢ç®¡é“"""
        self.logger.info("="*60)
        self.logger.info("Starting YOLOv5 to RKNN conversion pipeline")
        self.logger.info(f"Input model: {pytorch_path}")
        self.logger.info(f"Output directory: {output_dir}")
        self.logger.info(f"Input size: {input_size}")
        self.logger.info(f"Quantization: {'Enabled' if quantize else 'Disabled'}")
        self.logger.info("="*60)
        
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶è·¯å¾„
            model_name = os.path.splitext(os.path.basename(pytorch_path))[0]
            onnx_path = os.path.join(output_dir, f"{model_name}.onnx")
            rknn_path = os.path.join(output_dir, f"{model_name}.rknn")
            
            # Step 1: åŠ è½½PyTorchæ¨¡å‹
            self.logger.info("Step 1/3: Loading PyTorch model...")
            model = self.load_pytorch_model(pytorch_path)
            
            # Step 2: è½¬æ¢ä¸ºONNX
            self.logger.info("Step 2/3: Converting to ONNX...")
            if not self.export_to_onnx(model, onnx_path, input_size):
                raise RuntimeError("ONNX conversion failed")
            
            # Step 3: è½¬æ¢ä¸ºRKNN
            self.logger.info("Step 3/3: Converting to RKNN...")
            if not self.convert_to_rknn(onnx_path, rknn_path, [list(input_size)], quantize):
                raise RuntimeError("RKNN conversion failed")
            
            # æˆåŠŸæ€»ç»“
            self.logger.info("="*60)
            self.logger.info("ğŸ‰ CONVERSION COMPLETED SUCCESSFULLY!")
            self.logger.info("="*60)
            self.logger.info(f"âœ… ONNX Model: {onnx_path}")
            self.logger.info(f"âœ… RKNN Model: {rknn_path}")
            
            if os.path.exists(onnx_path):
                onnx_size = os.path.getsize(onnx_path) / (1024 * 1024)
                self.logger.info(f"ğŸ“Š ONNX Size: {onnx_size:.1f} MB")
            
            if os.path.exists(rknn_path):
                rknn_size = os.path.getsize(rknn_path) / (1024 * 1024)
                self.logger.info(f"ğŸ“Š RKNN Size: {rknn_size:.1f} MB")
            
            self.logger.info("ğŸ“‹ Next Steps:")
            self.logger.info(f"   1. Copy {rknn_path} to RK3588")
            self.logger.info("   2. Use RKNN model for NPU inference")
            self.logger.info("   3. Expected performance: 15-30 FPS on RK3588")
            
            return True
            
        except Exception as e:
            self.logger.error("="*60)
            self.logger.error("âŒ CONVERSION FAILED!")
            self.logger.error("="*60)
            self.logger.error(f"Error: {e}")
            traceback.print_exc()
            return False

def main():
    parser = argparse.ArgumentParser(description='YOLOv5 to RKNN Model Converter')
    parser.add_argument('--input', type=str, required=True, 
                       help='Input PyTorch model path (.pt file)')
    parser.add_argument('--output', type=str, required=True,
                       help='Output directory for converted models')
    parser.add_argument('--input-size', type=int, default=640,
                       help='Input image size (default: 640)')
    parser.add_argument('--quantize', action='store_true',
                       help='Enable quantization for smaller model size')
    parser.add_argument('--verbose', action='store_true',
                       help='Enable verbose logging')
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ Input file not found: {args.input}")
        sys.exit(1)
    
    # æ„é€ è¾“å…¥å°ºå¯¸
    input_size = (1, 3, args.input_size, args.input_size)
    
    # åˆ›å»ºè½¬æ¢å™¨
    converter = YOLOv5ToRKNN(verbose=args.verbose)
    
    # å¼€å§‹è½¬æ¢
    success = converter.convert_full_pipeline(
        args.input, 
        args.output, 
        input_size, 
        args.quantize
    )
    
    if success:
        print("\nğŸ‰ Model conversion completed successfully!")
        sys.exit(0)
    else:
        print("\nâŒ Model conversion failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()