#!/usr/bin/env python3
"""
RK3588 RKNNæ¨¡å‹è½¬æ¢è„šæœ¬
å°†YOLOv5 PyTorchæ¨¡å‹è½¬æ¢ä¸ºRKNNæ ¼å¼ä»¥ä½¿ç”¨NPUåŠ é€Ÿ
"""

import os
import sys
import torch
import numpy as np
from rknn.api import RKNN
import cv2

class RKNN_Model_Converter:
    def __init__(self):
        self.rknn = RKNN()
        
    def convert_pytorch_to_onnx(self, pytorch_model_path, onnx_model_path, input_size=(1, 3, 640, 640)):
        """å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼"""
        print(f"ğŸ”„ è½¬æ¢PyTorchæ¨¡å‹åˆ°ONNX...")
        
        try:
            # åŠ è½½PyTorchæ¨¡å‹
            model = torch.hub.load('ultralytics/yolov5', 'custom', path=pytorch_model_path)
            model.eval()
            
            # åˆ›å»ºç¤ºä¾‹è¾“å…¥
            dummy_input = torch.randn(input_size)
            
            # å¯¼å‡ºONNX
            torch.onnx.export(
                model,
                dummy_input,
                onnx_model_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output'],
                dynamic_axes={
                    'input': {0: 'batch_size'},
                    'output': {0: 'batch_size'}
                }
            )
            print(f"âœ… ONNXæ¨¡å‹ä¿å­˜åˆ°: {onnx_model_path}")
            return True
        except Exception as e:
            print(f"âŒ ONNXè½¬æ¢å¤±è´¥: {e}")
            return False
    
    def convert_onnx_to_rknn(self, onnx_model_path, rknn_model_path, quantize=True):
        """å°†ONNXæ¨¡å‹è½¬æ¢ä¸ºRKNNæ ¼å¼"""
        print(f"ğŸ”„ è½¬æ¢ONNXæ¨¡å‹åˆ°RKNN...")
        
        try:
            # é…ç½®RKNN
            print('--> é…ç½®æ¨¡å‹')
            self.rknn.config(
                mean_values=[[0, 0, 0]],
                std_values=[[255, 255, 255]],
                target_platform='rk3588',
                quantized_algorithm='normal',
                quantized_method='channel' if quantize else None,
                optimization_level=3
            )
            print('é…ç½®å®Œæˆ')
            
            # åŠ è½½ONNXæ¨¡å‹
            print('--> åŠ è½½ONNXæ¨¡å‹')
            ret = self.rknn.load_onnx(model=onnx_model_path)
            if ret != 0:
                print('åŠ è½½ONNXæ¨¡å‹å¤±è´¥ï¼')
                return False
            print('åŠ è½½å®Œæˆ')
            
            # æ„å»ºæ¨¡å‹
            print('--> æ„å»ºæ¨¡å‹')
            ret = self.rknn.build(do_quantization=quantize)
            if ret != 0:
                print('æ„å»ºæ¨¡å‹å¤±è´¥ï¼')
                return False
            print('æ„å»ºå®Œæˆ')
            
            # å¯¼å‡ºRKNNæ¨¡å‹
            print(f'--> å¯¼å‡ºRKNNæ¨¡å‹åˆ° {rknn_model_path}')
            ret = self.rknn.export_rknn(rknn_model_path)
            if ret != 0:
                print('å¯¼å‡ºRKNNæ¨¡å‹å¤±è´¥ï¼')
                return False
            print('å¯¼å‡ºå®Œæˆ')
            
            return True
        except Exception as e:
            print(f"âŒ RKNNè½¬æ¢å¤±è´¥: {e}")
            return False
    
    def test_rknn_model(self, rknn_model_path, test_image_path):
        """æµ‹è¯•RKNNæ¨¡å‹æ¨ç†"""
        print(f"ğŸ§ª æµ‹è¯•RKNNæ¨¡å‹...")
        
        try:
            # åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ
            print('--> åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ')
            ret = self.rknn.init_runtime()
            if ret != 0:
                print('åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒå¤±è´¥')
                return False
            print('è¿è¡Œæ—¶ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ')
            
            # åŠ è½½æµ‹è¯•å›¾åƒ
            if os.path.exists(test_image_path):
                img = cv2.imread(test_image_path)
                img = cv2.resize(img, (640, 640))
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                # æ¨ç†
                print('--> æ‰§è¡Œæ¨ç†')
                outputs = self.rknn.inference(inputs=[img])
                print(f'æ¨ç†è¾“å‡ºå½¢çŠ¶: {[output.shape for output in outputs]}')
                print('âœ… RKNNæ¨¡å‹æµ‹è¯•æˆåŠŸ')
                return True
            else:
                print(f'æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image_path}')
                return False
                
        except Exception as e:
            print(f"âŒ RKNNæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def convert_complete_pipeline(self, pytorch_model_path, output_dir="./rknn_models"):
        """å®Œæ•´çš„è½¬æ¢æµç¨‹"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        model_name = os.path.splitext(os.path.basename(pytorch_model_path))[0]
        onnx_path = os.path.join(output_dir, f"{model_name}.onnx")
        rknn_path = os.path.join(output_dir, f"{model_name}.rknn")
        
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„æ¨¡å‹è½¬æ¢æµç¨‹")
        print(f"è¾“å…¥: {pytorch_model_path}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print("-" * 50)
        
        # æ­¥éª¤1: PyTorch -> ONNX
        if not os.path.exists(onnx_path):
            if not self.convert_pytorch_to_onnx(pytorch_model_path, onnx_path):
                return False
        else:
            print(f"âœ… ONNXæ¨¡å‹å·²å­˜åœ¨: {onnx_path}")
        
        # æ­¥éª¤2: ONNX -> RKNN
        if not os.path.exists(rknn_path):
            if not self.convert_onnx_to_rknn(onnx_path, rknn_path):
                return False
        else:
            print(f"âœ… RKNNæ¨¡å‹å·²å­˜åœ¨: {rknn_path}")
        
        print("ğŸ‰ æ¨¡å‹è½¬æ¢å®Œæˆï¼")
        print(f"ONNXæ¨¡å‹: {onnx_path}")
        print(f"RKNNæ¨¡å‹: {rknn_path}")
        
        return True
    
    def __del__(self):
        if hasattr(self, 'rknn'):
            self.rknn.release()

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='RK3588 RKNNæ¨¡å‹è½¬æ¢å·¥å…·')
    parser.add_argument('--input', type=str, default='./best.pt', help='è¾“å…¥PyTorchæ¨¡å‹è·¯å¾„')
    parser.add_argument('--output', type=str, default='./rknn_models', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--test-image', type=str, help='æµ‹è¯•å›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # åˆ›å»ºè½¬æ¢å™¨
    converter = RKNN_Model_Converter()
    
    # æ‰§è¡Œè½¬æ¢
    success = converter.convert_complete_pipeline(args.input, args.output)
    
    if success and args.test_image:
        # æµ‹è¯•æ¨¡å‹
        model_name = os.path.splitext(os.path.basename(args.input))[0]
        rknn_path = os.path.join(args.output, f"{model_name}.rknn")
        converter.test_rknn_model(rknn_path, args.test_image)
    
    if success:
        print("\nâœ… è½¬æ¢å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨RKNNæ¨¡å‹è¿›è¡ŒNPUåŠ é€Ÿæ¨ç†äº†")
        print("\nä½¿ç”¨æ–¹æ³•:")
        model_name = os.path.splitext(os.path.basename(args.input))[0]
        rknn_path = os.path.join(args.output, f"{model_name}.rknn")
        print(f"python3 detect_rknn.py --source 0 --weights {rknn_path}")
    else:
        print("âŒ è½¬æ¢å¤±è´¥")
        sys.exit(1)

if __name__ == '__main__':
    main()